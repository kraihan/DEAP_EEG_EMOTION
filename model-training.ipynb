{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df2351d-524e-43e8-a58c-bc178eed52cc",
   "metadata": {},
   "source": [
    "# 3D CNN for emotion recognition from eeg dataset \n",
    "## This training is done using DEAP dataset\n",
    "### You can try it with SEED, Gameemo, Dreamers or others one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77ddc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:40:45.522573Z",
     "iopub.status.busy": "2025-03-27T04:40:45.522313Z",
     "iopub.status.idle": "2025-03-27T04:40:45.529527Z",
     "shell.execute_reply": "2025-03-27T04:40:45.528499Z",
     "shell.execute_reply.started": "2025-03-27T04:40:45.522543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf you find this helpful, kindly cite this.\\n\\n@article{KHAN2025107826,\\ntitle = {A comparative study of time–frequency features based spatio-temporal analysis with varying multiscale kernels for emotion recognition from EEG},\\njournal = {Biomedical Signal Processing and Control},\\nvolume = {107},\\npages = {107826},\\nyear = {2025},\\nissn = {1746-8094},\\ndoi = {https://doi.org/10.1016/j.bspc.2025.107826},\\nurl = {https://www.sciencedirect.com/science/article/pii/S1746809425003374},\\nauthor = {Md Raihan Khan, Airin Akter Tania,  Mohiuddin Ahmad},\\n}\\n\\n\\n@INPROCEEDINGS{10499496,\\n  author={Khan, Md Raihan and Ahmad, Mohiuddin},\\n  booktitle={2024 International Conference on Advances in Computing, Communication, Electrical, and Smart Systems (iCACCESS)}, \\n  title={Mental Stress Detection from EEG Signals Using Comparative Analysis of Random Forest and Recurrent Neural Network}, \\n  year={2024},\\n  volume={},\\n  number={},\\n  pages={1-6},\\n  doi={10.1109/iCACCESS61735.2024.10499496}}\\n  \\n  \\nFor full text paper or any other information kindly mail to kraihan918@gmail.com  \\n  '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "If you find this helpful, kindly cite this.\n",
    "\n",
    "@article{KHAN2025107826,\n",
    "title = {A comparative study of time–frequency features based spatio-temporal analysis with varying multiscale kernels for emotion recognition from EEG},\n",
    "journal = {Biomedical Signal Processing and Control},\n",
    "volume = {107},\n",
    "pages = {107826},\n",
    "year = {2025},\n",
    "issn = {1746-8094},\n",
    "doi = {https://doi.org/10.1016/j.bspc.2025.107826},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/S1746809425003374},\n",
    "author = {Md Raihan Khan, Airin Akter Tania,  Mohiuddin Ahmad},\n",
    "}\n",
    "\n",
    "\n",
    "@INPROCEEDINGS{10499496,\n",
    "  author={Khan, Md Raihan and Ahmad, Mohiuddin},\n",
    "  booktitle={2024 International Conference on Advances in Computing, Communication, Electrical, and Smart Systems (iCACCESS)}, \n",
    "  title={Mental Stress Detection from EEG Signals Using Comparative Analysis of Random Forest and Recurrent Neural Network}, \n",
    "  year={2024},\n",
    "  volume={},\n",
    "  number={},\n",
    "  pages={1-6},\n",
    "  doi={10.1109/iCACCESS61735.2024.10499496}}\n",
    "  \n",
    "  \n",
    "For full text paper or any other information kindly mail to kraihan918@gmail.com  \n",
    "  \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47090d90",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690c99d1-13a0-4cbd-a7b3-a12f5bee35b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:40:57.169669Z",
     "iopub.status.busy": "2025-03-27T04:40:57.169326Z",
     "iopub.status.idle": "2025-03-27T04:40:57.174462Z",
     "shell.execute_reply": "2025-03-27T04:40:57.173752Z",
     "shell.execute_reply.started": "2025-03-27T04:40:57.169640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor Training on other features, just use that location\\n\"/kaggle/input/deap-research/DE\", \"/kaggle/input/deap-research/XCOR\", \"/kaggle/input/deap-research/PLV\"\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For Training on other features, just use that location\n",
    "\"/kaggle/input/deap-research/DE\", \"/kaggle/input/deap-research/XCOR\", \"/kaggle/input/deap-research/PLV\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01728658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:41:11.000176Z",
     "iopub.status.busy": "2025-03-27T04:41:10.999873Z",
     "iopub.status.idle": "2025-03-27T04:41:58.704940Z",
     "shell.execute_reply": "2025-03-27T04:41:58.704146Z",
     "shell.execute_reply.started": "2025-03-27T04:41:11.000149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataLoaded:\n",
      "(1280, 1024, 60)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "frameNum = 60 \n",
    "\n",
    "# load data\n",
    "dfs = []\n",
    "for i in range(1,33):\n",
    "  for j in range(1,41):\n",
    "    filename = 'All Features _ deap-research/Wavelet_Energy/subject_%d_trial_%d.csv'%(i,j)\n",
    "    cols = [i for i in range(frameNum)]\n",
    "    df = pd.read_csv(filename, header = None, usecols = cols, delimiter=',')   \n",
    "    dfs.append(df.values)\n",
    "    #print('participant%dvideo%d.txt'%(i,j))\n",
    "\n",
    "dfs = np.array(dfs)\n",
    "print('dataLoaded:')\n",
    "print(dfs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791a679c",
   "metadata": {},
   "source": [
    "### Normalize data for better training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a85c9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:51:32.041407Z",
     "iopub.status.busy": "2025-03-27T04:51:32.041085Z",
     "iopub.status.idle": "2025-03-27T04:51:33.454488Z",
     "shell.execute_reply": "2025-03-27T04:51:33.453715Z",
     "shell.execute_reply.started": "2025-03-27T04:51:32.041381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25600, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "x_min = dfs.min(axis = (1,2),keepdims=True)\n",
    "x_max = dfs.max(axis = (1,2),keepdims=True)\n",
    "dfs_normal = (dfs-x_min)/(x_max-x_min)\n",
    "depth = 3\n",
    "# divide frames ,or 60s is too long for a single 3dinput\n",
    "reshape_dfs = np.split(dfs_normal, frameNum/depth, axis=2)\n",
    "reshape_dfs = np.array(reshape_dfs)\n",
    "reshape_dfs = np.reshape(reshape_dfs,[-1,1024,depth])\n",
    "print(reshape_dfs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa23876-8bb2-4859-9694-07232249c0c0",
   "metadata": {},
   "source": [
    "### Load and Handle label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7c567b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:42:24.949935Z",
     "iopub.status.busy": "2025-03-27T04:42:24.949649Z",
     "iopub.status.idle": "2025-03-27T04:42:24.972322Z",
     "shell.execute_reply": "2025-03-27T04:42:24.971593Z",
     "shell.execute_reply.started": "2025-03-27T04:42:24.949913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 4)\n",
      "(25600,)\n"
     ]
    }
   ],
   "source": [
    "# load label\n",
    "cols = ['valence', 'arousal', 'dominance', 'liking']\n",
    "label_df = pd.read_csv('All Features _ deap-research/label.txt', #'All Features _ deap-research/label.txt',\n",
    "    usecols = [i for i in range(4)], header=None, delimiter=',')\n",
    "print(label_df.shape)\n",
    "label_df.columns = cols\n",
    "label_df[label_df<5] = 0\n",
    "label_df[label_df>=5] = 1\n",
    "\n",
    "#(1280, 4)\n",
    "\n",
    "# valence\n",
    "label = label_df['valence'].astype(int).values\n",
    "label = np.tile(label,20)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7522dc5-dc67-4797-8732-a2fc1dfb7caa",
   "metadata": {},
   "source": [
    "### Define 3d CNN model using pytorch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc1bf37-5950-47bb-a712-13df609c8065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:48:33.435777Z",
     "iopub.status.busy": "2025-03-27T04:48:33.435490Z",
     "iopub.status.idle": "2025-03-27T04:48:33.440733Z",
     "shell.execute_reply": "2025-03-27T04:48:33.439834Z",
     "shell.execute_reply.started": "2025-03-27T04:48:33.435755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor paper output, train with diffrent kernel size \\nFor kernel size 3, each line should be\\nself.conv11 = nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\\n\\nFor kernel size 5, padding size will be 2 \\nand for kernel size 7, padding size will be 3\\n\\n\\nTry with diffrent kernel size\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For paper output, train with diffrent kernel size \n",
    "For kernel size 3, each line should be\n",
    "self.conv11 = nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "For kernel size 5, padding size will be 2 \n",
    "and for kernel size 7, padding size will be 3\n",
    "\n",
    "\n",
    "Try with diffrent kernel size\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82163ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:48:41.345746Z",
     "iopub.status.busy": "2025-03-27T04:48:41.345438Z",
     "iopub.status.idle": "2025-03-27T04:48:41.353898Z",
     "shell.execute_reply": "2025-03-27T04:48:41.352704Z",
     "shell.execute_reply.started": "2025-03-27T04:48:41.345721Z"
    }
   },
   "outputs": [],
   "source": [
    "class cnn_classifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv11 = nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "    self.conv12 = nn.Conv3d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "    self.pool1 = nn.MaxPool3d(kernel_size=2, padding=(0,0,1))\n",
    "    \n",
    "    self.conv21 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "    self.conv22 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "    self.pool2 = nn.MaxPool3d(kernel_size=2, padding=(0,0,1))\n",
    "    \n",
    "    self.conv31 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=2)\n",
    "    self.conv32 = nn.Conv3d(in_channels=128, out_channels=128, kernel_size=5, stride=1, padding=2)\n",
    "    self.pool3 = nn.MaxPool3d(kernel_size=2, padding=0)\n",
    "    \n",
    "\n",
    "    self.fc_layer = nn.Linear(128*4*4*1, 2)\n",
    "    \n",
    "    self.dropout_layer = nn.Dropout(p=0.5)\n",
    "\n",
    "  def forward(self, xb):\n",
    "    h1 = self.conv11(xb)\n",
    "    h1 = self.conv12(h1)\n",
    "    h1 = self.dropout_layer(h1)\n",
    "    h1 = self.pool1(h1)\n",
    "    h1 = F.relu(h1)\n",
    "\n",
    "    h2 = self.conv21(h1)\n",
    "    h2 = self.conv22(h2)\n",
    "    #h2 = self.dropout_layer(h2)\n",
    "    h2 = self.pool2(h2)\n",
    "    h2 = F.relu(h2) \n",
    "\n",
    "    h3 = self.conv31(h2)\n",
    "    h3 = self.conv32(h3)\n",
    "    #h3 = self.dropout_layer(h3)\n",
    "    h3 = self.pool3(h3)\n",
    "    h3 = F.relu(h3) \n",
    "    \n",
    "    \n",
    "    # flatten the output from conv layers before feeind it to FC layer\n",
    "    flatten = h3.view(-1, 128*4*4*1)\n",
    "    out = self.fc_layer(flatten)\n",
    "    #out = self.dropout_layer(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935a1e7-ddbe-4280-a8b8-3d9d565e8baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T00:20:23.403490Z",
     "iopub.status.busy": "2025-03-27T00:20:23.403192Z",
     "iopub.status.idle": "2025-03-27T00:20:23.407337Z",
     "shell.execute_reply": "2025-03-27T00:20:23.406361Z",
     "shell.execute_reply.started": "2025-03-27T00:20:23.403467Z"
    }
   },
   "source": [
    "###  Define a function to train the model with GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cac8b48f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:49:22.381421Z",
     "iopub.status.busy": "2025-03-27T04:49:22.381003Z",
     "iopub.status.idle": "2025-03-27T04:49:22.389193Z",
     "shell.execute_reply": "2025-03-27T04:49:22.388252Z",
     "shell.execute_reply.started": "2025-03-27T04:49:22.381386Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=50 , batch_size=32, lr=0.0001, weight_decay=0):\n",
    "  # data\n",
    "  train_dataset = TensorDataset(x_train, y_train)\n",
    "  train_data_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "  # loss function\n",
    "  loss_func = F.cross_entropy\n",
    "\n",
    "  # optimizer\n",
    "  #optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "  # figure\n",
    "  train_a = list([])\n",
    "  test_a = list([])\n",
    "\n",
    "  # training loop\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    tic = time.time()\n",
    "    acc_train = []\n",
    "    for xb, yb in train_data_loader:    \n",
    "      xb, yb = xb.to(device), yb.to(device)\n",
    "      pred = model(xb)\n",
    "      loss = loss_func(pred, yb)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      acc_train.append(pred.detach().argmax(1).eq(yb).float().mean().cpu().numpy())\n",
    "    acc_train = np.mean(acc_train)\n",
    "    toc = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      model.eval()\n",
    "      y_pred = model(x_test.to(device))\n",
    "      acc = y_pred.argmax(1).eq(y_test.to(device)).float().mean().cpu().numpy()\n",
    "\n",
    "    train_a.append(acc_train)\n",
    "    test_a.append(acc)\n",
    "    print('Loss at epoch %d : %f, train_acc: %f, test_acc: %f, running time: %d'% (epoch, loss.item(), acc_train, acc, toc-tic))\n",
    "  \n",
    "  train_amax = max(train_a)\n",
    "  test_amax = max(test_a)\n",
    "\n",
    "  # draw an accuray figure\n",
    "  \"\"\"\n",
    "  plt.plot(train_a,'y.-.')\n",
    "  plt.plot(test_a,'.-.')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('accuracy')\"\"\"\n",
    "  plt.plot(train_a, 'y.-.', label='Train Accuracy')  # Add label for train accuracy\n",
    "  plt.plot(test_a, '.-.', label='Test Accuracy')    # Add label for test accuracy\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()  # Enable legend\n",
    "  plt.title('Train vs Test Accuracy Over Epochs')  # Add title\n",
    "  #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "  return train_amax,test_amax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18546a00-1869-4201-9b50-2c410fd982fc",
   "metadata": {},
   "source": [
    "### Defining some initials   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3de495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:51:41.295992Z",
     "iopub.status.busy": "2025-03-27T04:51:41.295693Z",
     "iopub.status.idle": "2025-03-27T04:51:41.300446Z",
     "shell.execute_reply": "2025-03-27T04:51:41.299681Z",
     "shell.execute_reply.started": "2025-03-27T04:51:41.295968Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Tracking variables for best fold\n",
    "best_fold_idx = -1\n",
    "best_test_acc = -1\n",
    "best_fold_train_acc = [0]\n",
    "best_fold_test_acc = []\n",
    "best_fold_losses = []\n",
    "best_y_true = None\n",
    "best_y_pred = None\n",
    "best_y_scores = None\n",
    "\n",
    "# K-fold validation\n",
    "x_train = reshape_dfs\n",
    "y_train = label\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c430a8d-09b4-43be-a104-b3c9a3e3864b",
   "metadata": {},
   "source": [
    "### Train the model with 10 fold cross validation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80af2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:55:19.048695Z",
     "iopub.status.busy": "2025-03-27T04:55:19.048372Z",
     "iopub.status.idle": "2025-03-27T04:55:19.053994Z",
     "shell.execute_reply": "2025-03-27T04:55:19.052911Z",
     "shell.execute_reply.started": "2025-03-27T04:55:19.048671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFrom here You can fixed epoch number, fold number, batch size, learning rate etc\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "From here You can fixed epoch number, fold number, batch size, learning rate etc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddca99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:55:25.139298Z",
     "iopub.status.busy": "2025-03-27T04:55:25.138869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "train acuracy 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fold_idx = 0\n",
    "for train_index, test_index in kf.split(x_train, y_train):  \n",
    "    print(f\"Fold {fold_idx}:\")\n",
    "    print(f\"train acuracy {best_fold_train_acc[fold_idx]}\")\n",
    "    \n",
    "    \n",
    "    # Splitting the data\n",
    "    x_train_fold = x_train[train_index]\n",
    "    y_train_fold = y_train[train_index]\n",
    "    x_test_fold = x_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    x_train_fold = torch.from_numpy(x_train_fold).float()\n",
    "    y_train_fold = torch.from_numpy(y_train_fold).long()\n",
    "    x_test_fold = torch.from_numpy(x_test_fold).float()\n",
    "    y_test_fold = torch.from_numpy(y_test_fold).long()\n",
    "    \n",
    "    # Initialize model\n",
    "    model = cnn_classifier()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Lists to store accuracies and losses for each fold\n",
    "    train_acc_per_fold = []\n",
    "    test_acc_per_fold = []\n",
    "    losses_per_fold = []\n",
    "\n",
    "    # Training loop\n",
    "    def train_model(model, x_train, y_train, x_test, y_test, epochs=50 , batch_size=32, lr=0.0001, weight_decay=0):\n",
    "        train_dataset = TensorDataset(x_train, y_train)\n",
    "        train_data_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "        # Loss function\n",
    "        loss_func = F.cross_entropy\n",
    "        # Optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            toc = time.time()\n",
    "            acc_train = []\n",
    "            epoch_loss = 0\n",
    "            for xb, yb in train_data_loader:    \n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                pred = model(xb)\n",
    "                loss = loss_func(pred, yb)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                acc_train.append(pred.detach().argmax(1).eq(yb).float().mean().cpu().numpy())\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            acc_train = np.mean(acc_train)\n",
    "            tic = time.time()\n",
    "            train_acc_per_fold.append(acc_train)\n",
    "            losses_per_fold.append(epoch_loss / len(train_data_loader))  # Avg loss\n",
    "\n",
    "            # Evaluate on test set\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(x_test.to(device)).argmax(1)\n",
    "                acc_test = y_pred.eq(y_test.to(device)).float().mean().cpu().numpy()\n",
    "                test_acc_per_fold.append(acc_test)\n",
    "                \n",
    "            #print('Loss at epoch %d : %f, train_acc: %f, test_acc: %f, running time: %d'% (epoch, loss.item(), acc_train, acc_test, toc-tic))\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    train_model(model, x_train_fold.view(-1, 1, 32, 32, depth), y_train_fold,\n",
    "                x_test_fold.view(-1, 1, 32, 32, depth), y_test_fold)\n",
    "    \n",
    "    # After training, check if this fold has the best test accuracy\n",
    "    if max(test_acc_per_fold) > best_test_acc:\n",
    "        best_test_acc = max(test_acc_per_fold)\n",
    "        best_fold_idx = fold_idx\n",
    "        best_fold_train_acc = train_acc_per_fold\n",
    "        best_fold_test_acc = test_acc_per_fold\n",
    "        best_fold_losses = losses_per_fold\n",
    "\n",
    "        # Save the best fold's predictions for further evaluation\n",
    "        best_y_true = y_test_fold.cpu().numpy()\n",
    "        best_y_pred = model(x_test_fold.view(-1, 1, 32, 32, depth).to(device)).argmax(dim=1).cpu().numpy()\n",
    "        best_y_scores = model(x_test_fold.view(-1, 1, 32, 32, depth).to(device)).softmax(dim=1)[:, 1].detach().cpu().numpy()\n",
    "\n",
    "    \n",
    "    fold_idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4a346-f464-4dba-a62a-089b35f94954",
   "metadata": {},
   "source": [
    "### Plot loss and acuracy Curve \n",
    "### For paper purpose save the traning, testing loss and accuracy in csv file and plot manually with proper smooting\n",
    "### This techniques provieds greater results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e932d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# After k-fold, evaluate and plot results for the best fold\n",
    "print(f\"Best Fold: {best_fold_idx}, Test Accuracy: {best_test_acc}\")\n",
    "\n",
    "# Plot training and test accuracy for the best fold\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(best_fold_train_acc) + 1), best_fold_train_acc, label='Train Accuracy', color='blue')\n",
    "plt.title('Accuracy vs Epochs of Wavelet Energy (Valence)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (Kernel 5x5)')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(best_fold_losses) + 1), best_fold_losses, label='Loss', color='red')\n",
    "plt.title('Loss vs Epochs of Wavelet Energy (Valence)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (Kernel 5x5)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978341a9-0726-47c1-a6b0-3362e972d414",
   "metadata": {},
   "source": [
    "### Plot confusion matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a66f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for best fold\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(best_y_true, best_y_pred, title='Confusion Matrix of Wavelet Energy (Valence) with Kernel 5x5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5184e-7bb2-4b83-b800-e3a5b4119795",
   "metadata": {},
   "source": [
    "### Print Classification Reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report for best fold\n",
    "print('Classification Report of Wavelet Energy (Valence) with Kernel 5x5:')\n",
    "print(classification_report(best_y_true, best_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296817d1-dc46-4bc0-a9da-5cadd9dbb1ef",
   "metadata": {},
   "source": [
    "### Plot ROC Curve  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc14881-3e64-42ef-8bfc-6bd18a839771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for best fold\n",
    "def plot_roc_curve(y_true, y_scores):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "    np.savetxt('roc_curve_Wavelet_Energy_valence_5ker.txt', np.c_[fpr, tpr], header='FPR TPR', comments='')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) of Wavelet Energy with Kernel 5x5 (Valence)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(best_y_true, best_y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcac227-3834-4fd8-a0cc-1c1c89406d8c",
   "metadata": {},
   "source": [
    "### Save the model for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cddee5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T00:26:39.584505Z",
     "iopub.status.busy": "2025-03-27T00:26:39.584167Z",
     "iopub.status.idle": "2025-03-27T00:26:39.613614Z",
     "shell.execute_reply": "2025-03-27T00:26:39.613008Z",
     "shell.execute_reply.started": "2025-03-27T00:26:39.584477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model saved to cnn_classifier_wavelet_energy_arousal_full_3.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "model_save_path = \"cnn_classifier_wavelet_energy_arousal_full_3.pth\"\n",
    "torch.save(model, model_save_path)\n",
    "print(f\"Full model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd5985-d900-42c5-8863-80bfc1088257",
   "metadata": {},
   "source": [
    "### Load the model and reuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54515de3-0cc1-4b39-b3b3-e248760c4e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T00:26:42.885795Z",
     "iopub.status.busy": "2025-03-27T00:26:42.885509Z",
     "iopub.status.idle": "2025-03-27T00:26:42.904829Z",
     "shell.execute_reply": "2025-03-27T00:26:42.903918Z",
     "shell.execute_reply.started": "2025-03-27T00:26:42.885774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model loaded and ready for inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-db150a735b84>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(\"/kaggle/working/cnn_classifier_wavelet_energy_arousal_full_3.pth\")\n"
     ]
    }
   ],
   "source": [
    "# Load the entire model\n",
    "loaded_model = torch.load(\"/kaggle/working/cnn_classifier_wavelet_energy_arousal_full_3.pth\")\n",
    "loaded_model.eval()  # Set model to evaluation mode\n",
    "print(\"Full model loaded and ready for inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e1e5f1-8ad3-4fe2-bdb2-a357a77609a5",
   "metadata": {},
   "source": [
    "### Check Model Usability\n",
    "\n",
    "##### Though checking using trained data, it does not indicates performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0eac2c84-a9b3-49d4-9ed2-f5016c1aaa39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T00:26:45.371858Z",
     "iopub.status.busy": "2025-03-27T00:26:45.371529Z",
     "iopub.status.idle": "2025-03-27T00:26:45.436810Z",
     "shell.execute_reply": "2025-03-27T00:26:45.435813Z",
     "shell.execute_reply.started": "2025-03-27T00:26:45.371829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "New data shape (raw): (1, 1024, 60)\n",
      "New data shape (normalized): (1, 1024, 60)\n",
      "New data shape (reshaped): (20, 32, 32, 3)\n",
      "Predicted classes: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-6fb8c59bd5ec>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(\"cnn_classifier_wavelet_energy_arousal_full_3.pth\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "frameNum = 60\n",
    "depth = 3  # Should match the training data structure\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the model\n",
    "loaded_model = torch.load(\"cnn_classifier_wavelet_energy_arousal_full_3.pth\")\n",
    "loaded_model.eval()\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Load the new data\n",
    "filename = '/kaggle/input/deap-research/Wavelet_Energy/participant1video10.txt'\n",
    "cols = [i for i in range(frameNum)]\n",
    "df = pd.read_csv(filename, header=None, usecols=cols, delimiter=',')\n",
    "dfs = [df.values]  # Assuming this file has a structure like your training dataset\n",
    "\n",
    "# Convert to numpy array\n",
    "dfs = np.array(dfs)\n",
    "print(f\"New data shape (raw): {dfs.shape}\")\n",
    "\n",
    "# Normalize the data (use min-max scaling, similar to training)\n",
    "x_min = dfs.min(axis=(1, 2), keepdims=True)\n",
    "x_max = dfs.max(axis=(1, 2), keepdims=True)\n",
    "dfs_normal = (dfs - x_min) / (x_max - x_min)\n",
    "print(f\"New data shape (normalized): {dfs_normal.shape}\")\n",
    "\n",
    "# Reshape the data to match the CNN input format\n",
    "reshape_dfs = np.split(dfs_normal, frameNum // depth, axis=2)  # Divide into depth slices\n",
    "reshape_dfs = np.array(reshape_dfs)\n",
    "reshape_dfs = np.reshape(reshape_dfs, [-1, 32, 32, depth])  # Example shape adjustment\n",
    "print(f\"New data shape (reshaped): {reshape_dfs.shape}\")\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "data_tensor = torch.from_numpy(reshape_dfs).float().unsqueeze(1)  # Add channel dimension\n",
    "data_tensor = data_tensor.to(device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions = loaded_model(data_tensor)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1).cpu().numpy()\n",
    "\n",
    "# Output predictions\n",
    "print(f\"Predicted classes: {predicted_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282dcd2-9984-4ca5-a3a5-2ca7fe522693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5819581,
     "sourceId": 9551391,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
